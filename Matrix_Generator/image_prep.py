

import numpy as np
import pandas as pd
import os
import string
import matplotlib.pyplot as plt
import csv
from tifffile import imread, imwrite, imshow
from scipy.signal import find_peaks

'''
Finds values in a numpy array that are between a minimum and maximum value.
Output values are returned as numpy.ndarray. 
'''
def array_between(numpy_array, min_threshold, max_threshold): 
    boolean_array = np.logical_and(numpy_array > min_threshold, numpy_array < max_threshold)
    in_range_indices = np.where(boolean_array)[0]
    in_range_values = np.empty((0))
    for i in in_range_indices: 
        in_range_values = np.append(in_range_values, numpy_array[i])
    return in_range_values

'''
In a 1D array of peaks generated by scipy.signal.find_peaks(), finds the corresponding minima on either side of the peaks. 
As input, takes a 1D array of peak values from find_peaks(array) and a 1D array of min values from find_peaks(array*-1). 
Returns two dictionaries showing the previous and next minima on either side of a particular peak. 
'''
def mins_between_peaks(peaks_array, mins_array): 
    #where peaks_array contains indices of peaks in an image
    next_mins_dict = {}
    previous_mins_dict = {}

    inter_peak_spaces = np.empty(0, dtype = int)
    for i, peak in enumerate(peaks_array[0:-1]):
        next_peak = peaks_array[i + 1]
        next_mins = array_between(mins_array, peak, next_peak)
        next_min = next_mins.mean()

        next_mins_dict[peak] = next_min
        previous_mins_dict[next_peak] = next_min

        inter_peak_space = next_peak - peak
        inter_peak_spaces = np.append(inter_peak_spaces, inter_peak_space)

    inter_peak_space = inter_peak_spaces.mean()
    previous_mins_dict[peaks_array[0]] = peaks_array[0] - (inter_peak_space / 2)
    next_mins_dict[peaks_array[-1]] = peaks_array[-1] + (inter_peak_space / 2)

    return previous_mins_dict, next_mins_dict

'''
Takes a complete spot array image as a 2D numpy array and slices it into images of each individual spot. 
To do this, it takes inputs of the indices of vertical and horizontal line peaks and minima. 
If render_sliced_image is set to True, it will also draw a new image showing the slice lines. 
'''
def image_slicer(image_ndarray, vlinepeaks_indices, vlinemins_indices, hlinepeaks_indices, hlinemins_indices, render_sliced_image = True, verbose = False, slicer_debugging = False):
    if render_sliced_image: 
        max_pixel = image_ndarray.max()

        #By copying the image into all the channels, the spots will remain white
        red_channel = image_ndarray.copy()
        green_channel = image_ndarray.copy()
        blue_channel = image_ndarray.copy()

    alphabet = list(string.ascii_uppercase) #Used for declaring coordinates later

    vlpeaks_prev_mins, vlpeaks_next_mins = mins_between_peaks(vlinepeaks_indices, vlinemins_indices)
    hlpeaks_prev_mins, hlpeaks_next_mins = mins_between_peaks(hlinepeaks_indices, hlinemins_indices)

    peak_coordinates_dict = {}
    sliced_spot_dict = {}
    for i, horizontal_peak in enumerate(hlinepeaks_indices): 
        row_letter = alphabet[i]
        for j, vertical_peak in enumerate(vlinepeaks_indices): 
            col_number = j + 1
            alphanumeric_coordinates = row_letter + str(col_number)

            horizontal_prev_min = int(hlpeaks_prev_mins.get(horizontal_peak)) #horizontal peaks are along the vertical axis
            horizontal_next_min = int(hlpeaks_next_mins.get(horizontal_peak))
            vertical_prev_min = int(vlpeaks_prev_mins.get(vertical_peak)) #vertical peaks are along the horizontal axis
            vertical_next_min = int(vlpeaks_next_mins.get(vertical_peak))

            peak_coordinates = (horizontal_peak, vertical_peak) #(height, width)
            peak_coordinates_dict[alphanumeric_coordinates] = peak_coordinates

            sliced_spot = image_ndarray[horizontal_prev_min:horizontal_next_min, vertical_prev_min:vertical_next_min] #height range, width range
            if slicer_debugging: 
                imshow(sliced_spot, cmap="gray")
                plt.show()

            top_left_corner = (horizontal_prev_min, vertical_prev_min) #height x width
            sliced_spot_dict[alphanumeric_coordinates] = (top_left_corner, sliced_spot)

    if render_sliced_image: 
        #Mark peaks with blue lines
        for horizontal_peak in hlinepeaks_indices: 
            blue_channel[horizontal_peak, :] = max_pixel
            red_channel[horizontal_peak, :] = 0
            green_channel[horizontal_peak, :] = 0
        for vertical_peak in vlinepeaks_indices: 
            blue_channel[:, vertical_peak] = max_pixel
            red_channel[:, vertical_peak] = 0
            green_channel[:, vertical_peak] = 0

        #Mark mins (borders) with red lines
        for horizontal_min in hlinemins_indices: 
            red_channel[horizontal_min, :] = max_pixel
            green_channel[horizontal_min, :] = 0
            blue_channel[horizontal_min, :] = 0
        for vertical_min in vlinemins_indices: 
            red_channel[:, vertical_min] = max_pixel
            green_channel[:, vertical_min] = 0
            blue_channel[:, vertical_min] = 0


    if render_sliced_image: 
        return peak_coordinates_dict, sliced_spot_dict, red_channel, green_channel, blue_channel
    else: 
        return peak_coordinates_dict, sliced_spot_dict

'''
Evaluates whether a point defined by (x,y) is within a defined ellipsoid. 
The ellipsoid is defined by the equation x^2+y^2=1, with scaling factors. 
Returns a truth value for whether the point is inside the ellipsoid. 
'''
def ellipsoid_evaluator(x, y, a, b, c, d, return_value = False, eval_verbose = False): 
    if eval_verbose: 
        print("\t\t\tx =", x, "and y =", y, "| a =", a, ", b =", b, ", c =", c, ", d =", d)
    
    value = ((x-c)**2)/(a**2) + ((y-d)**2)/(b**2)
    
    if eval_verbose: 
        print("\t\t\t((x-c)**2)/(a**2) + ((y-d)**2)/(b**2) =", value)

    if value <= 1: 
        inside = True
    elif value > 1: 
        inside = False
    else: 
        raise Exception("\t\t\tellipsoid_evaluator error: value is not a number")

    if eval_verbose: 
        print("\t\t\tinside =", inside)

    if return_value: 
        return value, inside
    else: 
        return inside

'''
Simple function to take a list of peaks from find_peaks() and collapse it to a single mean peak.
Input: 
    peaks = list of peaks
    values = the values that find_peaks() was originally applied to
Output: 
    peak = a single integer
'''
def collapse_peaks(peaks, values): 
    if len(peaks) > 0: 
        peak = round(peaks.mean())
    else: 
        print("\t\t\tWarning: no peaks; defaulting to center.")
        peak = round(len(values) / 2)
    return peak

#Simple function to check if a peak index is within the tolerated bounds, and if not, nudge it to the inner edge of the bounds.
def nudge_peak(peak, tolerated_variance, spot_midpoint): 
    if peak < (spot_midpoint - tolerated_variance): 
        peak = spot_midpoint - tolerated_variance
    elif peak > (spot_midpoint + tolerated_variance): 
        peak = spot_midpoint + tolerated_variance
    return peak

#Finds the distance to the nearest border to a given index in a range of indices.
def nearest_border(index, length, verbose = False):
    if (index - 0) <= (length - index): 
        radius = index - 0
        if verbose: 
            print("\t\t\tradius from distance to index[0]:", radius)
    else: 
        radius = length - index
        if verbose:
            print("\t\t\tradius from distance to index[-1]:", radius)
    return radius

'''
Finds the center and radii of a sliced spot image.
Marks the centre of the spot as the intersection of the peak values for horizontal and vertical summed lines in the image array. 
If more than one peak is found in either the horizontal or vertical dimension, the peaks are averaged. 
Inputs: 
    spot_image = the sliced spot image as a numpy array
    tolerance_fraction = a value from 0 to 1 for the allowed deviation from image center while finding peaks/crosshairs/actual spot center
        0 = no tolerance
        1 = total tolerance
    tolerance_mode = "whole" or "subslice"
        "whole": find_peaks applied to whole image and then nudged based on tolerance_fraction
        "subslice": find_peaks applied to subslice of spot image sliced based on tolerance_fraction
Returns: 
    peak_intersect = (height, width) as a point
    vertical_radius, horizontal_radius = the radii of the spot, defined by the distance to the nearest image border from the peak_intersect
'''
def center_spot(spot_image, tolerance_fraction, tolerance_mode = "whole", centering_verbose = False): 
    if centering_verbose: 
        print("\t\t\trunning center_spot()...")
        print("\t\t\tspot_image shape =", spot_image.shape)

    spot_image_height = len(spot_image)
    spot_image_width = len(spot_image[0])

    if centering_verbose: 
        print("\t\t\tspot_image_height =", spot_image_height)
        print("\t\t\tspot_image_width =", spot_image_width)
        print("\t\t\tfinding midpoints...")

    image_vertical_midpoint = round(spot_image_height / 2)
    image_horizontal_midpoint = round(spot_image_width / 2)

    if centering_verbose: 
        print("\t\t\timage_vertical_midpoint =", image_vertical_midpoint)
        print("\t\t\timage_horizontal_midpoint =", image_horizontal_midpoint)
        print("\t\t\tappying the tolerance_fraction of", tolerance_fraction)

    tolerated_vertical_variance = round(tolerance_fraction * image_vertical_midpoint)
    tolerated_horizontal_variance = round(tolerance_fraction * image_horizontal_midpoint)

    if centering_verbose: 
        print("\t\t\ttolerated_vertical_variance =", tolerated_vertical_variance)
        print("\t\t\ttolerated_horizontal_variance =", tolerated_horizontal_variance)
        print("\t\t\tfinding spot_vlinesums and spot_hlinesums...")

    if tolerance_mode == "subslice": 
        spot_vlinesums = spot_image[:,image_horizontal_midpoint - tolerated_horizontal_variance : image_horizontal_midpoint + tolerated_horizontal_variance].sum(axis = 0)
        spot_hlinesums = spot_image[image_vertical_midpoint - tolerated_vertical_variance : image_vertical_midpoint + tolerated_vertical_variance,:].sum(axis = 1)
    elif tolerance_mode == "whole": 
        spot_vlinesums = spot_image.sum(axis = 0)
        spot_hlinesums = spot_image.sum(axis = 1)
    else: 
        raise Exception("Error in center_spot: tolerance_mode \"" + tolerance_mode + "\" is not an accepted mode (expected \"whole\" or \"subslice\").")

    if centering_verbose: 
        print("\t\t\tspot_vlinesums:", spot_vlinesums)
        print("\t\t\tspot_hlinesums:", spot_hlinesums)

    #Note: find_peaks() is operating on a sliced image, so the peak indices must be adjusted afterwards
    spot_vlinepeaks, _ = find_peaks(spot_vlinesums)
    spot_hlinepeaks, _ = find_peaks(spot_hlinesums)

    if centering_verbose: 
        #Note that if tolerance_mode is "subslice", these values are unadjusted subslice indices
        print("\t\t\tspot_vlinepeaks:", spot_vlinepeaks)
        print("\t\t\tspot_hlinepeaks:", spot_hlinepeaks)
        print("\t\t\ttaking mean of peaks...")

    #Get single mean peak
    spot_vlinepeak = collapse_peaks(peaks = spot_vlinepeaks, values = spot_vlinesums)
    spot_hlinepeak = collapse_peaks(peaks = spot_hlinepeaks, values = spot_hlinesums)

    if centering_verbose: 
        print("\t\t\tspot_vlinepeak:", spot_vlinepeak)
        print("\t\t\tspot_hlinepeak:", spot_hlinepeak)

    if centering_verbose and tolerance_mode == "subslice": 
        print("\t\t\tperforming index adjustment...")

    if tolerance_mode == "subslice": 
        #Adjust indices of slice to apply to whole spot image
        spot_vlinepeak = spot_vlinepeak + (image_horizontal_midpoint - tolerated_horizontal_variance)
        spot_hlinepeak = spot_hlinepeak + (image_vertical_midpoint - tolerated_vertical_variance)
    elif tolerance_mode == "whole": 
        #Nudge indices to obey tolerance_fraction
        spot_vlinepeak = nudge_peak(peak = spot_vlinepeak, tolerated_variance = tolerated_horizontal_variance, spot_midpoint = image_horizontal_midpoint)
        spot_hlinepeak = nudge_peak(peak = spot_hlinepeak, tolerated_variance = tolerated_vertical_variance, spot_midpoint = image_vertical_midpoint)

    peak_intersect = (spot_hlinepeak, spot_vlinepeak)

    if centering_verbose: 
        print("\t\t\tcorrected spot_vlinepeak:", spot_vlinepeak)
        print("\t\t\tcorrected spot_hlinepeak:", spot_hlinepeak)
        print("\t\t\tpeak_intersect:", peak_intersect)

    #Find nearest distance to border and use this for the radius, for both dimensions

    if centering_verbose: 
        print("\t\t\tCalculating nearest distance to borders for use as vertical and horizontal radii...")

    vertical_radius = nearest_border(index = spot_hlinepeak, length = spot_image_height, verbose = True)
    horizontal_radius = nearest_border(index = spot_vlinepeak, length = spot_image_width, verbose = True)

    return peak_intersect, vertical_radius, horizontal_radius

'''
Accepts as input a dictionary of alphanumeric spot coordinates where the value is a tuple of (top_left_corner, spot_image): 
    top_left_corner = the coordinates of the top left corner of the sliced image in the original image it came from
    spot_image = a sliced image of a single spot as a 2D numpy array
For the centering parameter: 
    If set to True, it will invoke center_spot() to find the peak intersect point to define a surrounding ellipsoid. 
    If set to False, sets the center point of the spot as equal to the center point of the spot image for defining a surrounding ellipsoid. 
Optionally, a dilation_factor may be used as a multiplier to enlarge (>1) 
or constrict (<1) the defined constraining ellipsoid. 
The function returns a dictionary of alphanumeric spot coordinate keys, where the dictionary value is a tuple consisting of: 
    (background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner)
Where: 
    background_adjusted_signal = (sum of pixel values inside the ellipsoid) - (mean pixel value outside the ellipsoid)*(number of pixels inside the ellipsoid)
    ellipsoid_index = (mean pixel value inside the ellipsoid) / (mean pixel value outside the ellipsoid)
        Values >>> 1 represent signals which are highly constrained to the ellipsoid. 
        Values ~1 represent smears that are not ellipsoidal. 
        Values <1 usually represent situations where most of the signal is non-specific bleed-over from neighbouring spots. 
    peak_intersect = the coordinates of the center of the spot as (height, width)
    top_left_corner is the original top_left_corner value
'''
def ellipsoid_constrain(spot_images, dilation_factor = 1, centering = True, return_coordinates_list = False, constrain_verbose = False): 
    if constrain_verbose: 
        print("\t\t\trunning ellipsoid_constrain()...")

    output_dict = {}

    if return_coordinates_list: 
        coordinates_list = []

    for spot_coordinates, value in spot_images.items(): 
        top_left_corner, spot_image = value

        if constrain_verbose: 
            print("\t\t\ttop left corner of current spot:", top_left_corner)

        spot_image_height = len(spot_image)
        spot_image_width = len(spot_image[0])

        if constrain_verbose: 
            print("\t\t\tSpot image height: ", spot_image_height, "px")
            print("\t\t\tSpot image width: ", spot_image_width, "px")

        '''
        The ellipsoid equation is (x-c)^2/(a^2) + (y-d)^2/(b^2) = 1, where <1 is inside the ellipsoid, and >1 is outside. 
            a = horizontal radius (stretch)
            b = vertical radius (stretch)
            c = horizontal translation
            d = vertical translation
            The middle of the circle is a point at (c, d). 
                CAUTION: The coordinates are reversed for NumPy image arrays, which are a vertical list of horizontal lines. 
                For arrays, the midpoint is (d, c). Coordinates are effectively (y,x) rather than (x,y). 
        '''

        if centering:             
            peak_intersect, vertical_radius, horizontal_radius = center_spot(spot_image, centering_verbose = constrain_verbose, 
                tolerance_fraction = 0.5, tolerance_mode = "whole")

            if constrain_verbose: 
                print("\t\t\tpeak_intersect =", peak_intersect)
                print("\t\t\tvertical_radius =", vertical_radius)
                print("\t\t\thorizontal_radius =", horizontal_radius)
                print("\t\t\tapplying a dilation factor of", dilation_factor)

            vertical_radius = vertical_radius * dilation_factor
            horizontal_radius = horizontal_radius * dilation_factor

        else: 
            vertical_radius = round((spot_image_height / 2) * dilation_factor)
            horizontal_radius = round((spot_image_width / 2) * dilation_factor)
            peak_intersect = (vertical_radius, horizontal_radius)
            if constrain_verbose: 
                print("\t\t\tapplying a dilation factor of", dilation_factor)
                print("\t\t\tpeak_intersect =", peak_intersect)
                print("\t\t\tvertical_radius =", vertical_radius)
                print("\t\t\thorizontal_radius =", horizontal_radius)

        a = horizontal_radius
        b = vertical_radius
        c = peak_intersect[1]
        d = peak_intersect[0]

        if constrain_verbose: 
            print("\t\t\tThe inside-ellipsoid equation is (x-c)^2/(a^2) + (y-d)^2/(b^2) < 1")
            print("\t\t\tHere, the equation is (x-" + str(c) + ")^2/(" + str(a) + "^2) + (y-" + str(d) + ")^2/(" + str(b) + "^2) < 1, ")
            print("\t\t\twhere x and y are the pixel coordinates that may or may not be within the ellipsoid.")

        pixels_inside = 0
        pixels_outside = 0
        sum_intensities_inside = 0
        sum_intensities_outside = 0

        for i, row in enumerate(spot_image): 
            if constrain_verbose: 
                print("\t\t\tWorking on row", i, "of spot_image...")
            for j, pixel_value in enumerate(row): 
                if constrain_verbose: 
                    print("\t\t\tevaluating column index", j, "in this row...")
                    print("\t\t\tpixel_value is", pixel_value)

                pixel_is_inside = ellipsoid_evaluator(x = j, y = i, a = a, b = b, c = c, d = d, eval_verbose = constrain_verbose)

                if constrain_verbose: 
                    print("\t\t\tpixel_is_inside =", pixel_is_inside)

                if pixel_is_inside: 
                    pixels_inside += 1
                    sum_intensities_inside += pixel_value
                else: 
                    pixels_outside += 1
                    sum_intensities_outside += pixel_value

        mean_intensity_inside = sum_intensities_inside / pixels_inside
        mean_intensity_outside = sum_intensities_outside / pixels_outside

        #Assume that everything outside the circle is background, and subtract to get the true signal
        background_adjusted_signal = sum_intensities_inside - (pixels_inside * mean_intensity_outside)

        '''
        Make an index where >>>1 means strong positive, ~1 means negative/smear, 
        and <1 indicates that the majority of the signal comes from neighbouring spots bleeding over.
        '''
        ellipsoid_index = mean_intensity_inside / mean_intensity_outside

        #To the output dict, add a tuple containing the background-adjusted signal and the ellipsoid index
        output_dict[spot_coordinates] = (background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner)
        if return_coordinates_list: 
            coordinates_list.append(spot_coordinates)

    '''
    Returns a dictionary where the key is spot coordinates and the value is a tuple containing 
    (background-adjusted signal, ellipsoid index)
    '''
    if return_coordinates_list: 
        return output_dict, coordinates_list
    else: 
        return output_dict

'''
Function to draw crosshairs on the true peak points for each spot in the unsliced image. 
As input, takes: 
    image = an image as a numpy array
    spot_info = the dictionary returned by ellipsoid_constrain()
    crosshair_length = the length, in pixels, of the crosshair lines to be drawn
    crosshair_brightness = the brightness of the drawn crosshairs as a float pixel intensity (max. 1.0)
    crosshair_width = the width of the crosshair lines. Must be an odd integer; if not odd, +1 will be added. 
Returns the image with crosshairs drawn on all the spots. 
'''
def draw_crosshairs(channels, spot_info, crosshair_length, crosshair_brightness = 0.5, crosshair_width = 1): 
    red_channel, green_channel, blue_channel = channels
    max_green_pixel = green_channel.max()

    if crosshair_width % 2 == 0: 
        crosshair_width = crosshair_width + 1 #catches even widths

    deviation = int((crosshair_width - 1) / 2)

    for spot_coordinates, value_tuple in spot_info.items(): 
        background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner = value_tuple
        real_peak_intersect = (top_left_corner[0] + peak_intersect[0], top_left_corner[1] + peak_intersect[1])

        #Draw horizontal green crosshair
        green_channel[real_peak_intersect[0] - deviation : real_peak_intersect[0] + deviation, real_peak_intersect[1] - crosshair_length : real_peak_intersect[1] + crosshair_length] = max_green_pixel
        red_channel[real_peak_intersect[0] - deviation : real_peak_intersect[0] + deviation, real_peak_intersect[1] - crosshair_length : real_peak_intersect[1] + crosshair_length] = 0
        blue_channel[real_peak_intersect[0] - deviation : real_peak_intersect[0] + deviation, real_peak_intersect[1] - crosshair_length : real_peak_intersect[1] + crosshair_length] = 0

        #Draw vertical green crosshair
        green_channel[real_peak_intersect[0] - crosshair_length : real_peak_intersect[0] + crosshair_length, real_peak_intersect[1] - deviation : real_peak_intersect[1] + deviation] = max_green_pixel
        red_channel[real_peak_intersect[0] - crosshair_length : real_peak_intersect[0] + crosshair_length, real_peak_intersect[1] - deviation : real_peak_intersect[1] + deviation] = 0
        blue_channel[real_peak_intersect[0] - crosshair_length : real_peak_intersect[0] + crosshair_length, real_peak_intersect[1] - deviation : real_peak_intersect[1] + deviation] = 0

    channels = (red_channel, green_channel, blue_channel)

    return channels

'''
Define a function that graphs a list of sums of vertical or horizontal lines in an image and 
asks the user to define a list of maxima and minima. 
axis = 0 corresponds to sums of vertical lines across the horizontal axis
axis = 1 corresponds to sums of horizontal lines across the vertical axis
Returns numpy arrays of line_peakks and line_mins.
'''
def manual_peak_finder(line_sums, axis): 
    if axis == 0: 
        axis = "horizontal"
        line_axis = "vertical"
    elif axis == 1: 
        axis = "vertical"
        line_axis = "horizontal"
    else: 
        raise Exception("Error in manual_peak_finder(): axis value was " + str(axis) + ", expected 0 or 1.")

    print("\tShowing line graph of", line_axis, "line sums across the", axis, "axis of the image.")
    print("\tPlease note the positions of the peaks and minima between peaks. You will be prompted to enter them.")
    line_peaks, line_mins = np.empty(0), np.empty(0)
    plt.plot(line_sums)
    plt.xlabel("indices")
    plt.ylabel("pixel_intensity")
    plt.show()
    done_inputting_peaks = False
    while not done_inputting_peaks: 
        new_peak = input("Enter the next peak index (integer along x axis):  ")
        if new_peak == "": 
            done_inputting_peaks = True
        else: 
            new_peak = int(new_peak)
            line_peaks = np.append(line_peaks, new_peak)
        new_min = input("Enter the minimum (valley) to the right of " + str(new_peak) + ", or leave blank if it was the last peak:  ")
        if new_min == "": 
            done_inputting_peaks = True
        else: 
            new_min = int(new_min)
            line_mins = np.append(line_mins, new_min)

    return line_peaks, line_mins

'''
Infers line peak indices based on grid dimensions (length or width) when searching for actual peaks is not possible. 
As input, takes: 
    line_sums = vertical_line_sums or horizontal_line_sums
    grid_dimension_length = grid_width or grid_height, respectively
Important: 
    For infer_peaks() to generate valid results, input images must be cropped right to the border of the spots on all sides, with no extra black space
Outputs a NumPy array of peaks. 
'''
def infer_peaks(line_sums, expected_peaks, collapse_extra_peaks = False, detected_peaks = None, tolerance_spot_frac = 0.25):
    mean_spot_dimension = len(line_sums) / expected_peaks

    inferred_line_peaks = np.arange(expected_peaks) * mean_spot_dimension
    inferred_line_peaks = inferred_line_peaks + (mean_spot_dimension / 2) #starts halfway across the first inferred spot square, making the assumption that the peak is in the middle
    inferred_line_peaks = inferred_line_peaks.round().astype(int) #rounds and gives integers, as indices must be ints

    inferred_line_mins = np.arange(expected_peaks + 1) * mean_spot_dimension
    inferred_line_mins = inferred_line_mins.round().astype(int)
    if inferred_line_mins[-1] > (len(line_sums) - 1):
        inferred_line_mins[-1] = len(line_sums) - 1 #catches error where the ending number, rounded up, might otherwise go out of bounds

    if collapse_extra_peaks:
        print("\t\t\t\tcollapsing extra peaks...")
        print("\t\t\t\toriginal peaks:", detected_peaks)
        print("\t\t\t\toriginal peak count:", len(detected_peaks))
        peak_deltas = detected_peaks[1:] - detected_peaks[0:-1]
        tolerated_delta = mean_spot_dimension * tolerance_spot_frac
        print("\t\t\t\ttolerated_delta =", tolerated_delta)
        deltas_indices = np.where(peak_deltas <= tolerated_delta)[0]
        print("\t\t\t\tdeltas_indices =", deltas_indices)
        append_peaks = np.empty(0)
        remove_peaks = np.empty(0)
        print("\t\t\t\t---", "\n\t\t\t\tcollapsing qualifying peaks...")
        for delta_index in deltas_indices:
            print("\t\t\t\tcurrent delta index:", delta_index)
            print("\t\t\t\tcorresponding pair of peaks:", detected_peaks[delta_index], detected_peaks[delta_index + 1])
            mean_detected_peak = round((detected_peaks[delta_index] + detected_peaks[delta_index + 1]) / 2)
            print("\t\t\t\tmean:", mean_detected_peak)
            append_peaks = np.append(append_peaks, mean_detected_peak)
            remove_peaks = np.append(remove_peaks, [delta_index, delta_index + 1])
        print("\t\t\t\t---")
        append_peaks, remove_peaks = append_peaks.astype(int), remove_peaks.astype(int)
        print("\t\t\t\tpeaks indices to remove:", remove_peaks)
        print("\t\t\t\tpeaks to append:", append_peaks)
        detected_peaks = np.delete(detected_peaks, remove_peaks)
        detected_peaks = np.append(detected_peaks, append_peaks)
        line_peaks = np.sort(detected_peaks)
        print("\t\t\t\tnew list of peaks:", line_peaks)
        print("\t\t\t\tnew peak count:", len(line_peaks))
        line_mins = inferred_line_mins
    else:
        line_peaks = inferred_line_peaks
        line_mins = inferred_line_mins
    
    return line_peaks, line_mins

'''
Function to conditionally apply infer_peaks() when there is a mismatch between the detected peak count and the expected peak count. 
As input, it takes: 
    line_sums = array of vertical or horizontal line sums
    actual_peaks = the detected peaks
    actual_peaks_count = the number of detected peaks
    actual_mins - the detected mins
    expected_peaks_count = the number of peaks that are expected based on the grid dimensions (number of spots expected)
    line_axis_name = the line sum axis; must be "vertical" or "horizontal"
    tolerance_spot_frac = the fraction of the spot dimension (in pixels) that is the allowed distance between peaks for them to be declared mergeable
    extra_peaks_proportion = the fraction of the expected peak count that is allowed for the collapse_extra_peaks method to be used
It outputs: 
    output_line_peaks = new array of line peaks based on conditionally applying infer_peaks()
    output_line_mins = new array of line mins based on conditionally applying infer_peaks()
'''

def handle_mismatch(line_sums, actual_peaks, actual_mins, expected_peaks_count, line_axis_name, tolerance_spot_frac = 0.25, extra_peaks_proportion = 0.25):
    actual_peaks_count = len(actual_peaks)
    extra_peaks_ceiling = (extra_peaks_proportion + 1) * expected_peaks_count

    print("\t\t\tgrid_peak_finder warning: found", actual_peaks_count, line_axis_name, "line peaks, but", expected_peaks_count, "were expected.")

    if actual_peaks_count < expected_peaks_count or actual_peaks_count > extra_peaks_ceiling:
        print("\t\t\t\tinferring", line_axis_name, "line peaks from dimensions...")
        output_line_peaks, output_line_mins = infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count)
    elif actual_peaks_count > expected_peaks_count and actual_peaks_count <= extra_peaks_ceiling:
        print("\t\t\t\taveraging extra", line_axis_name, "line peaks that are within", tolerance_spot_frac * 100, "% of average spot dimension...")
        output_line_peaks, output_line_mins = infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count,
                                                              collapse_extra_peaks = True,
                                                              detected_peaks = actual_peaks,
                                                              tolerance_spot_frac = tolerance_spot_frac)
        if len(output_line_peaks) != expected_peaks_count:
            print("\t\t\t\tfailed to correct number of peaks by averaging within the tolerance; reverting to inferring peaks by grid dimensions...")
            output_line_peaks, output_line_mins = infer_peaks(line_sums=line_sums, expected_peaks=expected_peaks_count)
    else:
        output_line_peaks, output_line_mins = actual_peaks, actual_mins

    return output_line_peaks, output_line_mins

'''
Function to define the coordinates of the spot array grid. 
As input, takes: 
    image_ndarray = an image as a grayscale 2D numpy array
    grid_dimensions = a tuple of (number of spots in width, number of spots in height)
The function first creates lists of the pixel intensity sums of vertical and horizontal lines of pixels in the image. 
It then uses find_peaks() to find peaks and valleys in these lists. 
Outputs results as a tuple of (vertical_line_peaks, vertical_line_mins, horizontal_line_peaks, horizontal_line_mins) where: 
    vertical_line_peaks, vertical_line_mins = peaks and minima in the sums of vertical lines of pixels across the horizontal axis of the image
    horizontal_line_peaks, horizontal_line_mins = peaks and minima in the sums of horizontal lines of pixels across the vertical axis of the image
'''
def grid_peak_finder(image_ndarray, grid_dimensions, manual_prompt = False, grid_peak_verbose = False): 
    #grid_dimensions is a tuple or list
    grid_width, grid_height = grid_dimensions #refers to number of spot positions in the 2D blot

    max_intensity, min_intensity = image_ndarray.max(), image_ndarray.min()
    image_width, image_height = len(image_ndarray[0]), len(image_ndarray)

    vertical_line_sums, horizontal_line_sums = image_ndarray.sum(axis = 0), image_ndarray.sum(axis = 1)

    if manual_prompt: 
        print("\t---")
        print("\tManual Peak-Finding Mode")
        print("\t---")
        vertical_line_peaks, vertical_line_mins = manual_peak_finder(vertical_line_sums, axis = 0)
        horizontal_line_peaks, horizontal_line_mins = manual_peak_finder(horizontal_line_sums, axis = 0)
    else: 
        vertical_line_peaks, _ = find_peaks(vertical_line_sums)
        vertical_line_mins, _ = find_peaks(vertical_line_sums * -1)
        horizontal_line_peaks, _ = find_peaks(horizontal_line_sums)
        horizontal_line_mins, _ = find_peaks(horizontal_line_sums * -1)

    if len(vertical_line_peaks) != grid_width:
        vertical_line_peaks, vertical_line_mins = handle_mismatch(line_sums = vertical_line_sums, actual_peaks = vertical_line_peaks,
                                                                  actual_mins = vertical_line_mins, expected_peaks_count = grid_width,
                                                                  line_axis_name = "vertical", tolerance_spot_frac = 0.25)
    else:
        print("\t\t\tfound correct number of vertical line peaks")

    if len(horizontal_line_peaks) != grid_height:
        horizontal_line_peaks, horizontal_line_mins = handle_mismatch(line_sums = horizontal_line_sums, actual_peaks = horizontal_line_peaks,
                                                                      actual_mins = horizontal_line_mins, expected_peaks_count = grid_height,
                                                                      line_axis_name = "horizontal", tolerance_spot_frac = 0.25)
    else:
        print("\t\t\tfound correct number of horizontal line peaks")

    grid_peak_results = (vertical_line_peaks, vertical_line_mins, horizontal_line_peaks, horizontal_line_mins)

    return grid_peak_results

#Function to import an image from a path to a numpy array. 
def tiff_to_numpy(path): 
    img = imread(path)
    try: 
        z_shape = img.shape[2]
    except:
        z_shape = 1 #catches out-of-bounds errors when z=1

    if z_shape == 2 and img[:,:,1].mean() == 1: 
        print("\t\ttiff_to_numpy warning:", path.split("/")[-1], " has 2 layers.", "\n\t\t\t--> disregarding the second layer (mean_intensity = 1.0; probable alpha channel).")
        img = img[:,:,0]
    elif z_shape >= 2: 
        print("\t\ttiff_to_numpy warning:", path.split("/")[-1], "has multiple layers/channels, with", z_shape, "layers present.")
        print("\t\t\tMean signals in layers: ")
        for i in np.arange(z_shape): 
            mean_signal = img[:,:,i].mean()
            max_signal = img[:,:,i].max()
            print("\t\t\tLayer", i + 1, "mean =", mean_signal, "and max =", max_signal)
        layer_to_use = int(input("\t\t\tWhich layer/channel do you want to use?  "))
        img = img[:,:,layer_to_use-1]

    return img

#Function to reverse the log transform on an image such that intensity linearly correlates with luminance.
def reverse_log_transform(image_ndarray): 
    if image_ndarray.max() > 1: 
        raise Exception("Error in reverse_log_transform: image array values out of range (expected: float between 0 and 1)")
    array_squared = np.power(image_ndarray, 2)
    return array_squared

def parse_filename(file_name): 
    filename_elements = file_name.split("_")
    if "Copy" not in filename_elements[0] and "copy" not in filename_elements[0]: 
        raise Exception("Copy number not in filename (" + filename + "). Filename must begin with CopyX_ScanY_[name_of_probe]...")
    elif "Scan" not in filename_elements[1] and "scan" not in filename_elements[1]: 
        raise Exception("Sequential scan number not in filename (" + filename + "). Filename must begin with CopyX_ScanY_[name_of_probe]...")
    elif len(filename_elements) < 3: 
        raise Exception("Probe name not in filename (" + filename + "). Filename must begin with CopyX_ScanY_[name_of_probe]...")

    copy = filename_elements[0][4:]
    scan = filename_elements[1][4:]
    probe = filename_elements[2]

    return copy, scan, probe

def analyze_array(copy, scan, probe, array_image, verbose_analysis = False, show_sliced_image = False, show_crosshairs_image = False, show_individual_spot_images = False): 
    if verbose_analysis: 
        print("\tProcessing Copy:", copy, "Scan:", scan, "Probe:", probe, "| loop number:", i)
        print("\t\tfinding grid peaks...")
    
    vertical_line_peaks, vertical_line_mins, horizontal_line_peaks, horizontal_line_mins = grid_peak_finder(image_ndarray = array_image, grid_dimensions = spot_grid_dimensions)

    if verbose_analysis: 
        print("\t\tslicing image...")
    
    image_peak_coordinates, image_slices, sliced_red_channel, sliced_green_channel, sliced_blue_channel = image_slicer(image_ndarray = array_image, vlinepeaks_indices = vertical_line_peaks, 
        vlinemins_indices = vertical_line_mins, hlinepeaks_indices = horizontal_line_peaks, hlinemins_indices = horizontal_line_mins, 
        render_sliced_image = True, slicer_debugging = show_individual_spot_images)

    sliced_image = np.stack((sliced_red_channel, sliced_green_channel, sliced_blue_channel), axis = 2)

    if show_sliced_image: 
        imshow(sliced_image, cmap="gray")
        plt.show()

    if verbose_analysis: 
        print("\t\tcomputing background-adjusted signal and ellipsoid_index...")

    spot_info_dict = ellipsoid_constrain(spot_images = image_slices, dilation_factor = 1, centering = False, constrain_verbose = False)
        #Data structure: dict[spot_coordinates] = (background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner)

    #Draw crosshairs on the individual spot peaks, which may not perfectly align with the hlinepeaks and vlinepeaks intersect points
    if verbose_analysis: 
        print("\t\tmaking image highlighting detected spots...")
    
    channels = (sliced_red_channel, sliced_green_channel, sliced_blue_channel)

    channels_crosshairs = draw_crosshairs(channels = channels, spot_info = spot_info_dict, 
        crosshair_length = 5, crosshair_brightness = 0.5, crosshair_width = 3)

    sliced_image_crosshairs = np.stack(channels, axis = 2)

    if show_crosshairs_image: 
        imshow(sliced_image_crosshairs / sliced_image_crosshairs.max())
        plt.show()

    analyzed_array_tuple = (copy, scan, probe, array_image, spot_info_dict, sliced_image_crosshairs)

    return analyzed_array_tuple

#Function to convert a 2-column CSV file into a dictionary, where the first column holds keys and the second column holds values
def csv_to_dict(filepath):
    result = {}
    with open(filepath, 'r') as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            key = row[0]
            value = row[1]
            result[key] = value
    return result

#Function to append elements to the value of a key-value pair in a dictionary, where the value is a list
def dict_value_append(input_dict, key, element_to_append):
    if input_dict.get(key) == None:
        input_dict[key] = [element_to_append]
    else:
        value_list = input_dict.get(key)
        value_list.append(element_to_append)
        input_dict[key] = value_list

#---------------------------------------------------------------------------------------------------------------------------------------------

#Begin processing the images

print("Please enter the dimensions of the array (number of spots in width x number of spots in height).")
spot_grid_width = int(input("Width (number of spots):  "))
spot_grid_height = int(input("Height (number of spots):  "))
spot_grid_dimensions = (spot_grid_width, spot_grid_height)
print("-----------------------")

image_directory = input("Enter the full directory where TIFF images are stored: ")
filenames_list = os.listdir(image_directory)
print("Loading files...")
array_images = []
for filename in filenames_list: 
    print("\tLoading", filename)
    copy, scan, probe = parse_filename(filename)

    file_path = os.path.join(image_directory, filename)
    print("\t\trunning tiff_to_numpy()...")
    image_array = tiff_to_numpy(file_path)
    print("\t\tapplying reverse_log_transform()...")
    image_array = reverse_log_transform(image_array)

    array_tuple = (copy, scan, probe, image_array)
    array_images.append(array_tuple)
    print("\t\tdone")

print("-----------------------")
print("Extracting signals from array images...")

crosshairs_image_popup = input("Display images as popups as they are generated? (Y/N)  ")
if crosshairs_image_popup == "Y":
    crosshairs_image_popup = True
else:
    crosshairs_image_popup = False

analyzed_array_images = []

for i, array_tuple in enumerate(array_images): 
    print("---")
    print("processing array_tuple @ index =", i)

    copy, scan, probe, array_image = array_tuple

    analyzed_array_tuple = analyze_array(copy = copy, scan = scan, probe = probe, array_image = array_image, 
        verbose_analysis = True, show_sliced_image = False, show_crosshairs_image = crosshairs_image_popup, show_individual_spot_images = False)

    analyzed_array_images.append(analyzed_array_tuple)

#---------------------------------------------------------------------------------------------------------------------------------------------

print("Assembling dataframe and saving images...")

data_df = pd.DataFrame() #initialize blank dataframe

output_directory = os.path.join(os.getcwd(), "image_prep_output")
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

rlt_output_directory = os.path.join(output_directory, "reverse_log_transformed_images")
if not os.path.exists(rlt_output_directory):
    os.makedirs(rlt_output_directory)

crosshairs_output_directory = os.path.join(output_directory, "crosshairs-marked_spot_images")
if not os.path.exists(crosshairs_output_directory):
    os.makedirs(crosshairs_output_directory)

bas_cols_dict = {} #Dictionary of lists of background-adjusted signal column names, where the key is the probe name
ei_cols_dict = {} #Dictionary of lists of ellipsoid index column names, where the key is the probe name
new_cols_dict = {} #Dictionary that includes both of the above, along with the copy and scan numbers, in the form of (copy, scan, bas_col, ei_col)

for analyzed_array_tuple in analyzed_array_images: 
    copy, scan, probe, array_image, spot_info_dict, sliced_image_crosshairs = analyzed_array_tuple

    col_prefix = probe + "\nCopy " + str(copy) + "\nScan " + str(scan)
    bas_col = col_prefix + "\nBackground-Adjusted_Signal"
    ei_col = col_prefix + "\nEllipsoid_Index"

    #Assign column names to dict by probe name
    dict_value_append(bas_cols_dict, probe, bas_col)
    dict_value_append(ei_cols_dict, probe, ei_col)
    dict_value_append(new_cols_dict, probe, (copy, scan, bas_col, ei_col))

    #Assign dataframe values
    for spot_coord, signal_tuple in spot_info_dict.items(): 
        background_adjusted_signal, ellipsoid_index, _, _ = signal_tuple

        data_df.at[spot_coord, bas_col] = background_adjusted_signal
        data_df.at[spot_coord, ei_col] = ellipsoid_index

    #Save modified image
    imwrite(os.path.join(rlt_output_directory, "Copy" + str(copy) + "_Scan" + str(scan) + "_" + probe + "_reverse-log-transform.tif"), array_image)
    imwrite(os.path.join(crosshairs_output_directory, "Copy" + str(copy) + "_Scan" + str(scan) + "_" + probe + "_crosshairs.tif"), sliced_image_crosshairs)

#Declare probe order for sorting dataframe columns
probes_ordered = []
input_probe_order = input("Would you like to specify the order of probes for sorting columns? (Y/N)  ")
if input_probe_order == "Y":
    print("\tThe probes in this dataset are:", list(ei_cols_dict.keys()))
    print("\tPlease enter the probes in the order you wish them to appear. Hit enter when done.")
    no_more_probes = False
    while not no_more_probes:
        next_probe = input("Probe name:  ")
        if next_probe != "":
            probes_ordered.append(next_probe)
        else:
            no_more_probes = True
else:
    probes_ordered = list(ei_cols_dict.keys())
    print("\tUsing arbitrary probe order:", probes_ordered)

#Sorting dataframe and testing significance of hits
print("Organizing dataframe...")

sorted_cols = ["Peptide_Name"] #Adds a column to receive peptide names later
data_df.insert(0, "Peptide_Name", "")
for current_probe in probes_ordered:
    col_tuples = new_cols_dict.get(current_probe)
    col_tuples = sorted(col_tuples, key = lambda x: x[0]) #Sorts by copy number
    new_cols_dict[current_probe] = col_tuples
    for col_tuple in col_tuples:
        sorted_cols.append(col_tuple[2]) #Appends background_adjusted_signal column name
        sorted_cols.append(col_tuple[3]) #Appends ellipsoid_index column name
    data_df.insert(1, current_probe + "_call", "")
    sorted_cols.append(current_probe + "_call")

data_df = data_df[sorted_cols]

#Test significance
print("Testing significance of hits...")
ei_sig_thres = float(input("\tEnter the ellipsoid index threshold above which a hit is considered significant:  "))

for current_probe in probes_ordered:
    call_col = current_probe + "_call"
    ei_cols = ei_cols_dict.get(current_probe)
    data_df[call_col] = data_df.apply(lambda x: "Pass" if (x[ei_cols] > ei_sig_thres).all() else "", axis = 1)

#Add peptide names
add_names = input("Add peptide names from CSV file mapping coordinates to names? (Y/N)  ")
if add_names == "Y":
    names_path = input("\tEnter the path containing the CSV with coordinate-name pairs:  ")
    names_dict = csv_to_dict(names_path)
    print("Dictionary of coordinate-name pairs:")
    print(names_dict)

for i, row in data_df.iterrows():
    print("Row:", i)
    pep_name = names_dict.get(i)
    print("Peptide name:", pep_name)
    data_df.at[i, "Peptide_Name"] = pep_name

data_df.to_csv(os.path.join(output_directory, "preprocessed_data.csv"))

print("Done!")