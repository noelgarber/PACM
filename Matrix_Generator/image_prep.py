'''
This script performs image quantification of arrays of spots.
It was developed for SPOT peptide arrays, but it can be used for any image containing a grid of spots with rows and columns.
Note:   images inputted into this algorithm should be pre-straightened and cropped to the borders of the actual
        grid of spots. Leave no surrounding black space.
The data generated by this algorithm is compatible with the rest of the PACM pipeline.
'''

import numpy as np
import pandas as pd
import os
import string
import matplotlib.pyplot as plt
import csv
from Matrix_Generator.image_utils.hough_circle_detector import detect_circle as hough_detect_circle
from Matrix_Generator.image_utils.scan_optimal_circle import spot_circle_scan
from tifffile import imread, imwrite, imshow
from scipy.signal import find_peaks

def input_number(prompt, mode):
    if mode not in ["int", "float"]:
        raise Exception(f"input_number error: mode was set to {mode}, but either \"int\" or \"float\" was expected")

    input_finished = False
    output_value = None

    while not input_finished:
        input_value = input(prompt)
        try:
            if mode == "int":
                output_value = int(input_value)
                input_finished = True
            elif mode == "float":
                output_value = float(input_float)
                input_finished = True
        except:
            print(f"\tinput value was not an {mode}; please try again.")

    return output_value

#Function to convert a 2-column CSV file into a dictionary, where the first column holds keys and the second column holds values
def csv_to_dict(filepath):
    result = {}
    with open(filepath, 'r') as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            key = row[0]
            value = row[1]
            result[key] = value
    return result

#Function to append elements to the value of a key-value pair in a dictionary, where the value is a list
def dict_value_append(input_dict, key, element_to_append):
    if input_dict.get(key) == None:
        input_dict[key] = [element_to_append]
    else:
        value_list = input_dict.get(key)
        value_list.append(element_to_append)
        input_dict[key] = value_list

def concatenate_images(image_list):
    """
    Concatenates a list of small images into a larger image, using the top-left corner
    coordinates provided for each small image.

    Args:
        image_list (list): A list of tuples, where each tuple is (image, top_left_coords),
            where image is a 3D numpy array representing a color image, and top_left_coords
            is a tuple of (x, y) integers representing the top-left corner coordinates of
            that small image in the final concatenated image.

    Returns:
        numpy.ndarray: A 3D numpy array representing the concatenated image.
    """
    # Determine the size of the final concatenated image
    max_x, max_y = 0, 0
    for _, (x, y) in image_list:
        max_x = max(max_x, x + _.shape[0])
        max_y = max(max_y, y + _.shape[1])

    # Create a blank image of the correct size
    channels = image_list[0][0].shape[2]
    concatenated_image = np.zeros((max_x, max_y, channels), dtype=image_list[0][0].dtype)

    # Paste each small image onto the concatenated image at the correct location
    for image, (x, y) in image_list:
        concatenated_image[x:x + image.shape[0], y:y + image.shape[1], :] = image

    return concatenated_image

def draw_color_circle(image, midpoints, radius, circle_color = "green"):
    '''
    Simple function or drawing circle(s) of defined radius around a defined midpoint in a primary color.

    Args:
        image (np.ndarray): 2D (grayscale) or 3D (color) numpy array of floating points representing an image
        midpoints (list of tuples): one or more coordinates of the midpoint(s) of the circle(s), in (y,x) format
        radius (int): the radius of the circle; must not exceed the distance to the nearest border from the midpoint
        circle_color (str): the color of the circle to draw; default is green

    Returns:
        color_image (np.ndarray): 3D numpy array of floating points representing the image with the drawn circle
    '''

    # Convert 2D grayscale array to 3D color array
    if image.ndim == 2:
        color_image = np.stack([image]*3, axis=-1)
    elif image.ndim == 3:
        color_image = image
    else:
        raise Exception(f"draw_color_circle error: image has {image.ndim} dimensions, but 2 or 3 were expected.")

    # Define the color of the circle
    if circle_color in ["red", "Red", "r", "R"]:
        r, g, b = (image.max(), 0, 0)
    elif circle_color in ["green", "Green", "g", "G"]:
        r, g, b = (0, image.max(), 0)
    elif circle_color in ["blue", "Blue", "b", "B"]:
        r, g, b = (0, 0, image.max())
    else:
        raise Exception(f"draw_color_circle error: circle_color was given as {circle_color}, but must be one of [Red, Green, Blue, red, green, blue, R, G, B, r, g, b].")

    # Draw circle in green on the color image
    h, w = image.shape[:2]
    y_idxs, x_idxs = np.ogrid[:h, :w]
    for midpoint in midpoints:
        y, x = midpoint # assume numpy notation where (y,x) defines coordinates
        dists = np.sqrt((x_idxs - x)**2 + (y_idxs - y)**2)
        circle = (dists <= radius) & (dists >= radius-1)
        color_image[circle] = [r, g, b]

    return color_image

# Function that defines a circle on an image and counts the pixels and their sums inside and outside of the circle
def circle_stats(grayscale_image, center, radius):
    '''
    Function to obtain pixel counts/sums inside and outside of a defined circle

    Args:
        grayscale_image (np.ndarray): image as 2D numpy array
        center (tuple): pair of (x,y) values representing the center point of the circle; x=horizontal and y=vertical
        radius (int): the radius of the circle to define

    Returns:
        pixels_inside (np.int64): number of pixels inside the defined circle
        pixels_outside (np.int64): number of pixels outside the defined circle
        sum_inside (same dtype as input image, e.g. np.float16): sum of pixel values inside the circle
        sum_outside (same dtype as input image, e.g. np.float16): sum of pixel values outside the circle
    '''
    # Create a mesh grid of coordinates for the image
    x, y = np.meshgrid(np.arange(grayscale_image.shape[1]), np.arange(grayscale_image.shape[0]))

    # Calculate the distance between each pixel and the center
    distance = np.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)

    # Create a binary mask to identify the pixels inside the circle
    mask = distance <= radius

    # Flatten the image and mask arrays
    flat_image = grayscale_image.flatten()
    flat_mask = mask.flatten()

    # Count the number of pixels inside the circle and outside the circle
    pixels_inside = np.sum(flat_mask)
    pixels_outside = np.sum(~flat_mask)

    # Calculate the sum of pixel values inside the circle and outside the circle
    sum_inside = np.sum(flat_image[flat_mask])
    sum_outside = np.sum(flat_image[~flat_mask])

    # Calculate the ellipsoid index
    mean_intensity_inside = sum_inside / pixels_inside
    mean_intensity_outside = sum_outside / pixels_outside
    if mean_intensity_outside > 0:
        ellipsoid_index = mean_intensity_inside / mean_intensity_outside
    else:
        ellipsoid_index = "inf"

    # Find the background-adjusted sum of pixels inside the defined circle
    background_adjusted_inside_sum = sum_inside - (pixels_inside * mean_intensity_outside)

    return pixels_inside, pixels_outside, sum_inside, sum_outside, ellipsoid_index, background_adjusted_inside_sum


#---------------------------------------------------------------------------------------------------------------------------------------------

# Define a new SpotArray class for spot image arrays and associated data
class SpotArray:
    '''
    SpotArray class to contain spot image data and methods

    This class contains spot image data as 2D numpy arrays, metadata, and quantitation methods.

    Attributes:
        self.copy_number (str): the copy/replicate number, parsed from the filename
        self.scan_number (str): the scan order number, for when spot blots have been probed multiple times
        self.probe_name (str):  the name of the probe (e.g. a recombinant protein or antibody)

        self.grayscale_array (arr): original grayscale array from the inputted tiff image, as a 2D numpy array
        self.linear_array (arr):    grayscale_array with values squared, restoring linear luminance values

        self.sliced_image (arr):            the sliced image, without crosshairs, showing grid borders
        self.outlined_image (arr):          the sliced image with crosshairs added to mark spot centers
        self.spot_info_dict (dict):         key (str) [alphanumeric spot coordinates] =>
                                            (unadjusted_signal, background_adjusted_signal, ellipsoid_index,
                                            peak_intersect, top_left_corner)

    Methods:
        __init__(self, tiff_path, spot_dimensions, verbose, suppress_warnings): function to initialize a class object
        analyze_array(self, ellipsoid_dilation_factor, [options]): function that auto-runs to quantify the array, but
                                                                   can be run again with different settings afterwards
        reverse_log_transform(self, image_array, base): function to reverse logarithmic pixel encoding, restoring the
                                                        linear correlation between luminance and pixel value
        grid_peak_finder(self, show_line_sums, verbose): function to mark spots based on known grid dimensions; also
                                                         uses subsidiary functions handle_mismatch() and infer_peaks()

        #TODO Finish this docstring
    '''

    def __init__(self, tiff_path, spot_dimensions, metadata = (None, None, None), suppress_warnings = False, pixel_log_base = 1, verbose = False):
        '''
        Initialization function invoked when a new instance of the SpotArray class is created

        Args:
            tiff_path (str): the path to the tiff file where a spot image is stored
            spot_dimensions (tuple): a tuple of (number of spots in width, number of spots in height)
            metadata (tuple): a tuple of (probe_name, copy_number, scan_number)
            verbose (Boolean): whether to report initialization progress/steps in the terminal (default: False)
            suppress_warnings (Boolean): whether to suppress warnings that occur during initialization (default: False)
            pixel_log_base (int or float): if a logarithmic pixel encoding was used, this should be the logarithm's base

        Returns:
            None

        Raises:
            Warning: multiple layers found; uses the first layer when reading multi-layer TIFFs. Can be caused by an alpha-layer being present.
        '''
        self.grid_shape = spot_dimensions
        self.filename = os.path.basename(tiff_path).rsplit(".", 1)[0] # gets the filename without the extension
        self.probe_name, self.copy_number, self.scan_number = metadata

        # Initialize main grayscale image stored in tiff_path
        img = imread(tiff_path)
        try:
            layers = img.shape[2]
        except:
            layers = 1
        if layers > 1:
            img = img[:,:,0]
            print(f"\t\tCaution: {layers} layers were found when importing " + self.filename + ", but 1 was expected; the first layer was used.") if not suppress_warnings else None

        self.grayscale_array = img
        self.image_shape = img.shape[1], img.shape[0] #image_width, image_height
        self.linear_array = self.reverse_log_transform(img, base = pixel_log_base) # Ensures that pixel values linearly correlate with luminance

        # Analyze the array automatically with the default variables
        self.analyze_array(verbose = verbose)

    # High-level function that segments and analyzes the spots in the array
    def analyze_array(self, ellipsoid_dilation_factor = 1, show_sliced_image = False, show_outlined_image = False,
                      show_individual_spot_images = False, center_spots_mode = "iterative", verbose = True):
        '''
        Main function to analyze and quantify grids of spots

        Args:
            ellipsoid_dilation_factor (float): multiplier that dilates identified spot borders
            show_sliced_image (Boolean): whether to display the source image with gridlines after spot borders are found
            show_outlined_image (Boolean): whether to display the image with detected spots circled in green
            show_individual_spot_images (Boolean): whether to consecutively display individual spots for debugging
            center_spots_mode (Boolean): whether to assume that the center of an identified spot equals the center
                                         of the sliced spot image
            verbose (Boolean): whether to display progress information for debugging

        Returns:
            analyzed_array_tuple (tuple): (copy_number, scan_number, probe_name, linear_array, spot_info_dict,
                                           outlined_image)
        '''
        if verbose:
            print("\tProcessing: Copy", self.copy_number, " - Scan", self.scan_number, "- Probe", self.probe_name)
            print("\t\tfinding grid peaks...")

        # Find the indices of the vertical and horizontal maxima and minima
        self.vlpeaks_indices, self.vlmins_indices, self.hlinepeaks_indices, self.hlinemins_indices = self.grid_peak_finder(verbose = verbose)

        # Slice the image based on vertical and horizontal maxima and minima
        print("\t\tslicing image...") if verbose else None
        image_peak_coordinates, image_slices, self.sliced_image = self.image_slicer(image_ndarray = self.linear_array, vlinepeaks_indices = self.vlpeaks_indices, vlinemins_indices = self.vlmins_indices,
                                                                                    hlinepeaks_indices = self.hlinepeaks_indices, hlinemins_indices = self.hlinemins_indices,
                                                                                    render_sliced_image = True, slicer_debugging = show_individual_spot_images, verbose = verbose)

        # Display popup of sliced image if prompted
        if show_sliced_image:
            imshow(self.sliced_image)
            plt.show()

        # Make a dictionary holding alphanumeric spot coordinates as keys, storing tuples of (unadjusted_signal, background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner)
        print("\t\tcomputing background-adjusted signal and ellipsoid_index...") if verbose else None
        self.outlined_image, self.spot_info_dict = self.ellipsoid_constrain(spot_images = image_slices, dilation_factor = ellipsoid_dilation_factor, centering_mode = center_spots_mode, verbose = False)

        # Display popup of sliced image with drawn crosshairs if prompted
        if show_outlined_image:
            imshow(self.outlined_image / self.outlined_image.max())
            plt.show()

        # In addition to assigning to internal variables, also returns a tuple of results that can be optionally assigned when this function is invoked
        analyzed_array_tuple = (self.copy_number, self.scan_number, self.probe_name, self.linear_array, self.spot_info_dict, self.outlined_image)
        return analyzed_array_tuple

    '''
    ----------------------------------------------------------------------------------------------------
    The following are functions used by analyze_array(); they generally should not be used on their own.
    ----------------------------------------------------------------------------------------------------
    '''

    # Function to reverse the log transform on an image such that intensity linearly correlates with luminance
    def reverse_log_transform(self, array, base = 1):
        '''
        Applies the inverse log (exp) function to convert logarithmic pixel encoding to linear encoding

        Args:
            array: a 2D numpy array representing the image
            base:  the base of the logarithmic encoding scale, which varies depending on format and camera manufacturer
                   if base == "e", base will be set to 2.718281828459045 (inverse of natural logarithm)

        Returns:
            array_out: the modified 2D numpy array, where pixel values are linearly correlated with luminance

        Raises:
            Exception: image array values out of range (pixel values must be floats between 0 and 1)
        '''
        if base == "e":
            from math import e
            base = e
        if array.max() > 1:
            raise Exception("SpotArray.reverse_log_transform error: image array values out of range (expected: float between 0 and 1)")
        array_out = np.power(array, base)
        return array_out

    # Function to define the coordinates of the spot array grid.
    def grid_peak_finder(self, show_line_sums = False, verbose = False):
        '''
        Function to define the coordinates of the spot array grid.

        This function uses the handle_mismatch() and infer_peaks() methods in this class.
            - First creates lists of pixel value sums of vertical and horizontal lines of pixels in self.linear_array.
            - Then uses scipy.signal.find_peaks() to find peaks and valleys in these lists.

        Args:
            show_line_sums (Boolean): whether to show a plot of the vertical and horizontal line sums
            verbose (Boolean): whether to output additional information for debugging

        Returns:
            vertical_line_peaks (list of ints):   list of horizontal indices where peaks exist in summed vertical lines
            vertical_line_mins (list of ints):    list of horizontal indices where minima exist in summed vertical lines
            horizontal_line_peaks (list of ints): list of vertical indices where peaks exist in summed horizontal lines
            horizontal_line_mins (list of ints):  list of vertical indices where minima exist in summed horizontal lines
        '''
        grid_width, grid_height = self.grid_shape
        image_width, image_height = self.image_shape

        # Find the sums of vertical and horizontal lines of pixels in the grayscale image array
        vlsums, hlsums = self.linear_array.sum(axis=0), self.linear_array.sum(axis=1)

        if show_line_sums:
             print("\t\t\tShowing vertical line sums...")
             plt.plot(vlsums)
             plt.show()
             print("\t\t\tShowing horizontal line sums...")
             plt.plot(hlsums)
             plt.show()

        # Find peaks and valleys in the vertical and horizontal line sums
        vlpeaks, _ = find_peaks(vlsums)
        vlmins, _ = find_peaks(vlsums * -1)
        hlpeaks, _ = find_peaks(hlsums)
        hlmins, _ = find_peaks(hlsums * -1)

        # Find distances between adjacent indices of vertical and horizontal line peaks
        vlpeaks_deltas = vlpeaks[1:] - vlpeaks[:-1]
        hlpeaks_deltas = hlpeaks[1:] - hlpeaks[:-1]

        # Handle vertical line peaks (horizontal axis)
        vlpeaks, vlmins = self.check_line_peaks(line_axis_name = "vertical", line_sums = vlsums, line_peaks = vlpeaks, line_mins = vlmins,
                                                line_peaks_deltas = vlpeaks_deltas, expected_peaks_count = grid_width, length_px = image_width, verbose = True)
        hlpeaks, hlmins = self.check_line_peaks(line_axis_name = "horizontal", line_sums = hlsums, line_peaks = hlpeaks, line_mins = hlmins,
                                                line_peaks_deltas = hlpeaks_deltas, expected_peaks_count = grid_height, length_px = image_height, verbose = True)

        return vlpeaks, vlmins, hlpeaks, hlmins

    # Function to check whether detected vertical/horizontal line peaks match expected horizontal/vertical spot count
    def check_line_peaks(self, line_axis_name, line_sums, line_peaks, line_mins, line_peaks_deltas, expected_peaks_count, length_px, verbose = False):
        '''
        Function to check whether the detected line peaks match the number of expected spots and correct as necessary

        Args:
            line_axis_name (str): name of the axis of the line sums, i.e. "vertical" or "horizontal"
            line_sums (arr of floats): list of sums of lines of pixels along the orthogonal axis
            line_peaks (arr of ints): list of indices in line_sums where local peaks exist
            line_mins (arr of ints): list of indices in line_sums where local minima exist
            line_peaks_deltas (arr of ints): list of spacings between adjacent indices in line_peaks
            expected_peaks_count (int): expected number of peaks
            length_px (int): number of pixels in the image in the orthogonal axis to lines of pixels being summed
            verbose (Boolean): whether to output additional information for debugging

        Returns:
            line_peaks (arr of ints): adjusted input line_peaks depending on whether a mismatch was found
            line_mins (arr of ints): adjusted input line_mins depending on whether a mismatch was found
        '''
        if len(line_peaks) != expected_peaks_count:
            '''
            Mismatch handling for when the number of vertical/horizontal line peaks in the horizontal/vertical axis does 
            not equal the number of spots expected in the horizontal axis
            '''
            print(f"\t\t\tWarning: number of {line_axis_name} line peaks does not match expected peaks count (found {len(line_peaks)}, expected {expected_peaks_count}); invoking self.handle_mismatch()")
            line_peaks, line_mins = self.handle_mismatch(line_sums = line_sums, actual_peaks = line_peaks, actual_mins = line_mins,
                                                         expected_peaks_count = expected_peaks_count, line_axis_name = line_axis_name,
                                                         length_px = length_px, tolerance_spot_frac = 0.25, verbose = verbose)
        elif line_peaks_deltas.min() < (0.5 * len(line_sums) / expected_peaks_count) or line_peaks_deltas.max() > (1.5 * len(line_sums) / expected_peaks_count):
            '''
            Tests whether the spacing between vertical/horizontal line peaks is regular; if outside tolerances, reverts 
            to inferring peaks based on image size and known grid dimensions instead of actually identifying the peaks.
            '''
            print("\t\t\tWarning: irregular line peak spacing; defaulting to inferring peaks from grid dimensions")
            line_peaks, line_mins = self.infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count, verbose = verbose)
        else:
            print(f"\t\t\tfound correct number of {line_axis_name} line peaks") if verbose else None
        return line_peaks, line_mins

    # Function for resolving mismatches between detected peak counts and expected peak counts
    def handle_mismatch(self, line_sums, actual_peaks, actual_mins, expected_peaks_count, line_axis_name, length_px,
                        tolerance_spot_frac = 0.25, extra_peaks_proportion = 0.1, deltas_threshold = 1.5, verbose = False):
        '''
        Function to resolve mismatches between the detected peak count and the expected peak count.

        Args:
            line_sums (arr of floats): list of sums of lines of pixels along the orthogonal axis
            actual_peaks (arr of ints): the detected peaks (which are given as indices referring to the line_sums)
            actual_mins (arr of ints): the detected mins (indices referring to line_sums)
            expected_peaks_count (int): the number of peaks that are expected based on the grid dimensions (number of spots expected)
            line_axis_name (str): the line sum axis; must be "vertical" or "horizontal"
            tolerance_spot_frac (float): the fraction of the spot dimension (in pixels) that is the allowed distance between peaks for them to be declared mergeable
            extra_peaks_proportion (float): the fraction of the expected peak count that is allowed for the collapse_extra_peaks method to be used
            deltas_threshold (float or None): if float, it is used to test the distances between output line minima to ensure no aberrant differences
                                              default is 1.5, allowing 50% variance from mean distances between minima

        Returns:
            output_line_peaks (arr of ints): new array of line peaks based on conditionally applying infer_peaks()
            output_line_mins (arr of ints): new array of line mins based on conditionally applying infer_peaks()
        '''
        actual_peaks_count = len(actual_peaks)
        extra_peaks_ceiling = (extra_peaks_proportion + 1) * expected_peaks_count
        extra_peaks_ceiling = round(extra_peaks_ceiling)

        if actual_peaks_count < expected_peaks_count or actual_peaks_count > extra_peaks_ceiling:
            print("\t\t\t\tinferring", line_axis_name, "line peaks from dimensions...") if verbose else None
            output_line_peaks, output_line_mins = self.infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count, verbose = verbose)
        elif actual_peaks_count > expected_peaks_count and actual_peaks_count <= extra_peaks_ceiling:
            print("\t\t\t\taveraging extra", line_axis_name, "line peaks that are within", tolerance_spot_frac * 100, "% of average spot dimension...") if verbose else None
            output_line_peaks, output_line_mins = self.infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count, collapse_extra_peaks = True,
                                                                   detected_peaks=actual_peaks, tolerance_spot_frac = tolerance_spot_frac, verbose = verbose)
            print("\t\t\t\tgot", len(output_line_peaks), "line peaks and", len(output_line_mins), "line mins")

            if deltas_threshold is not None:
                line_mins_deltas = output_line_mins[1:] - output_line_mins[:-1]
                deltas_mean_expected = (length_px / expected_peaks_count) * deltas_threshold
                excessive_variance = any(line_mins_deltas > (deltas_threshold * deltas_mean_expected)) #boolean value
                print("\t\t\t\texcessive variances between line mins were detected...") if excessive_variance else None
            else:
                excessive_variance = False

            if len(output_line_peaks) != expected_peaks_count:
                print("\t\t\t\tfailed to correct number of peaks by averaging within the tolerance: wrong number of peaks found",
                      "\n\t\t\t\treverting to inferring peaks by grid dimensions...") if verbose else None
                output_line_peaks, output_line_mins = self.infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count, verbose = verbose)
            elif excessive_variance:
                print("\t\t\t\tfailed to correct number of peaks by averaging within the tolerance: excessive variance was detected",
                      "\n\t\t\t\treverting to inferring peaks by grid dimensions...") if verbose else None
                output_line_peaks, output_line_mins = self.infer_peaks(line_sums = line_sums, expected_peaks = expected_peaks_count, verbose = verbose)

        else:
            output_line_peaks, output_line_mins = actual_peaks, actual_mins

        return output_line_peaks, output_line_mins

    '''
    Infers line peak indices based on grid dimensions (length or width) when searching for actual peaks is not possible. 
    As input, takes: 
        line_sums = vertical_line_sums or horizontal_line_sums
        grid_dimension_length = grid_width or grid_height, respectively
    Important: 
        For infer_peaks() to generate valid results, input images must be cropped right to the border of the spots on all sides, with no extra black space
    Outputs a NumPy array of peaks. 
    '''
    def infer_peaks(self, line_sums, expected_peaks, collapse_extra_peaks = False, detected_peaks = None, tolerance_spot_frac = 0.25, verbose = False):
        mean_spot_dimension = len(line_sums) / expected_peaks

        inferred_line_peaks = np.arange(expected_peaks) * mean_spot_dimension
        inferred_line_peaks = inferred_line_peaks + (mean_spot_dimension / 2)  # starts halfway across the first inferred spot square, making the assumption that the peak is in the middle
        inferred_line_peaks = inferred_line_peaks.round().astype(int)  # rounds and gives integers, as indices must be ints

        inferred_line_mins = np.arange(expected_peaks + 1) * mean_spot_dimension
        inferred_line_mins = inferred_line_mins.round().astype(int)
        if inferred_line_mins[-1] > (len(line_sums) - 1):
            inferred_line_mins[-1] = len(line_sums) - 1  # catches error where the ending number, rounded up, might otherwise go out of bounds

        if collapse_extra_peaks:
            print("\t\t\t\tcollapsing extra peaks (detected " + str(len(detected_peaks)) + ")...")
            peak_deltas = detected_peaks[1:] - detected_peaks[0:-1]
            tolerated_delta = mean_spot_dimension * tolerance_spot_frac
            deltas_indices = np.where(peak_deltas <= tolerated_delta)[0]

            append_peaks = np.empty(0)
            remove_peaks = np.empty(0)
            for delta_index in deltas_indices:
                mean_detected_peak = round((detected_peaks[delta_index] + detected_peaks[delta_index + 1]) / 2)
                append_peaks = np.append(append_peaks, mean_detected_peak)
                remove_peaks = np.append(remove_peaks, [delta_index, delta_index + 1])
            append_peaks, remove_peaks = append_peaks.astype(int), remove_peaks.astype(int)

            line_peaks = detected_peaks.copy()
            line_peaks = np.delete(line_peaks, remove_peaks)
            line_peaks = np.append(line_peaks, append_peaks)
            line_peaks = np.sort(line_peaks)

            print("\t\t\t\tdone; collapsed", len(detected_peaks), "peaks to", len(line_peaks))

            line_mins = inferred_line_mins # Currently does not apply the collapse_extra_peaks method to minima, but this feature may be added in a later release
        else:
            line_peaks = inferred_line_peaks
            line_mins = inferred_line_mins

        return line_peaks, line_mins

    #-------------------------------------------------------------------------------------------------------------------------------------------------------
    '''
    Takes a complete spot array image as a 2D numpy array and slices it into images of each individual spot. 
    To do this, it takes inputs of the indices of vertical and horizontal line peaks and minima. 
    If render_sliced_image is set to True, it will also draw a new image showing the slice lines. 
    '''
    def image_slicer(self, image_ndarray, vlinepeaks_indices, vlinemins_indices, hlinepeaks_indices, hlinemins_indices,
                     render_sliced_image = True, slicer_debugging = False, verbose = False):
        print("\t\t\tstarting image_slicer()...") if verbose else None

        # Show the input image if slicer debugging is enabled
        if slicer_debugging:
            print("\t\t\tshowing input image...")
            imshow(image_ndarray, cmap="gray")
            plt.show()

        if render_sliced_image:
            max_pixel = image_ndarray.max()
            color_image = np.repeat(image_ndarray[:,:,np.newaxis], 3, axis=2) #Red=[:,:,0], Green=[:,:,1], Blue=[:,:,2]

        alphabet = list(string.ascii_uppercase)  # Used for declaring coordinates later

        print("\t\t\tfinding minima between line peaks (horizontal and vertical lines)...") if verbose else None
        vlpeaks_prev_mins, vlpeaks_next_mins = self.mins_between_peaks(vlinepeaks_indices, vlinemins_indices)
        hlpeaks_prev_mins, hlpeaks_next_mins = self.mins_between_peaks(hlinepeaks_indices, hlinemins_indices)

        print("\t\t\tfound", len(vlpeaks_prev_mins), "minima to the left and", len(vlpeaks_next_mins), "to the right of vlpeaks",
              "\n\t\t\tfound", len(hlpeaks_prev_mins), "minima to the left and", len(hlpeaks_next_mins), "to the right of hlpeaks") if verbose else None

        peak_coordinates_dict = {}
        sliced_spot_dict = {}
        for i, horizontal_peak in enumerate(hlinepeaks_indices):
            row_letter = alphabet[i]
            for j, vertical_peak in enumerate(vlinepeaks_indices):
                col_number = j + 1
                alphanumeric_coordinates = row_letter + str(col_number)

                horizontal_prev_min = int(hlpeaks_prev_mins.get(horizontal_peak))  # horizontal peaks are along the vertical axis
                horizontal_next_min = int(hlpeaks_next_mins.get(horizontal_peak))
                vertical_prev_min = int(vlpeaks_prev_mins.get(vertical_peak))  # vertical peaks are along the horizontal axis
                vertical_next_min = int(vlpeaks_next_mins.get(vertical_peak))

                peak_coordinates = (horizontal_peak, vertical_peak)  # (height, width)
                peak_coordinates_dict[alphanumeric_coordinates] = peak_coordinates

                sliced_spot = image_ndarray[horizontal_prev_min:horizontal_next_min,
                              vertical_prev_min:vertical_next_min]  # height range, width range

                # Define the coordinates of the top left corner, midpoint, and radius of a given image snippet in the source image (self.linear_array)
                top_left_corner = (horizontal_prev_min, vertical_prev_min)  # height x width (y,x)
                sliced_spot_midpoint = (round(sliced_spot.shape[0] / 2), round(sliced_spot.shape[1] / 2))
                sliced_spot_radius = min(sliced_spot_midpoint)

                # Derive the coordinates of the spot midpoint in the source image
                spot_midpoint_coords = (top_left_corner[0] + sliced_spot_midpoint[0], top_left_corner[1] + sliced_spot_midpoint[1])

                # Package the results into a dictionary
                values_at_coord = {
                    "top_left_corner": top_left_corner,
                    "spot_midpoint_coords": spot_midpoint_coords,
                    "spot_radius": sliced_spot_radius,
                    "spot_image_snippet": sliced_spot
                }

                # Assign the values dict to a dictionary with the alphanumeric coordinates as the key
                sliced_spot_dict[alphanumeric_coordinates] = values_at_coord

                if slicer_debugging:
                    print(f"\t\t\t{alphanumeric_coordinates} info: {values_at_coord}")
                    imshow(sliced_spot, cmap="gray")
                    plt.show()

        if render_sliced_image:
            # Mark peaks with blue lines
            for horizontal_peak in hlinepeaks_indices:
                color_image[:,:,2][horizontal_peak, :] = max_pixel
                color_image[:,:,0][horizontal_peak, :] = 0
                color_image[:,:,1][horizontal_peak, :] = 0
            for vertical_peak in vlinepeaks_indices:
                color_image[:,:,2][:, vertical_peak] = max_pixel
                color_image[:,:,0][:, vertical_peak] = 0
                color_image[:,:,1][:, vertical_peak] = 0

            # Mark mins (borders) with red lines
            for horizontal_min in hlinemins_indices:
                color_image[:,:,0][horizontal_min, :] = max_pixel
                color_image[:,:,1][horizontal_min, :] = 0
                color_image[:,:,2][horizontal_min, :] = 0
            for vertical_min in vlinemins_indices:
                color_image[:,:,0][:, vertical_min] = max_pixel
                color_image[:,:,1][:, vertical_min] = 0
                color_image[:,:,2][:, vertical_min] = 0

        if render_sliced_image:
            return peak_coordinates_dict, sliced_spot_dict, color_image
        else:
            return peak_coordinates_dict, sliced_spot_dict

    '''
    In a 1D array of peaks generated by scipy.signal.find_peaks(), finds the corresponding minima on either side of the peaks. 
    As input, takes a 1D array of peak values from find_peaks(array) and a 1D array of min values from find_peaks(array*-1). 
    Returns two dictionaries showing the previous and next minima on either side of a particular peak. 
    '''
    def mins_between_peaks(self, peaks_array, mins_array):
        # where peaks_array contains indices of peaks in an image

        next_mins_dict = {}
        previous_mins_dict = {}

        inter_peak_spaces = np.empty(0, dtype=int)
        for i, peak in enumerate(peaks_array[0:-1]):
            next_peak = peaks_array[i + 1]
            next_mins = self.array_between(mins_array, peak, next_peak)
            next_min = next_mins.mean()

            next_mins_dict[peak] = next_min
            previous_mins_dict[next_peak] = next_min

            inter_peak_space = next_peak - peak
            inter_peak_spaces = np.append(inter_peak_spaces, inter_peak_space)

        inter_peak_space = inter_peak_spaces.mean()
        previous_mins_dict[peaks_array[0]] = peaks_array[0] - (inter_peak_space / 2)
        next_mins_dict[peaks_array[-1]] = peaks_array[-1] + (inter_peak_space / 2)

        return previous_mins_dict, next_mins_dict

    '''
    Finds values in a numpy array that are between a minimum and maximum value.
    Output values are returned as np.ndarray. 
    '''
    def array_between(self, numpy_array, min_threshold, max_threshold):
        boolean_array = np.logical_and(numpy_array > min_threshold, numpy_array < max_threshold)
        in_range_indices = np.where(boolean_array)[0]
        in_range_values = np.empty((0))
        for i in in_range_indices:
            in_range_values = np.append(in_range_values, numpy_array[i])
        return in_range_values

    #-------------------------------------------------------------------------------------------------------------------------------------------------------

    def ellipsoid_constrain(self, spot_images, dilation_factor = 1, centering_mode = "iterative", return_coordinates_list = False, verbose = False):
        '''
        Function that returns a dictionary of spot coordinates where the value is a tuple of:
            unadjusted_signal (float): sum of pixel values inside the ellipse defining the spot
            background_adjusted_signal (float): sum of pixel values inside the spot ellipse, minus area-adjusted signal from outside the ellipse
            ellipsoid_index (float): the ratio of mean pixel values inside the spot ellipse to mean pixel values outside the ellipse
            spot_midpoint (tuple): a tuple representing coordinates of the center of the defined spot ellipse
            top_left_corner (tuple): a tuple representing coordinates of the top left corner of each spot image snippet
            stitched_image (np.ndarray): if hough_stitch mode is used, is an image showing the outlined detected spots

        The ellipsoid centering mode can be any of the following options:
            "hough": Hough circle transform method
            "hough_stitch": Hough circle transform, also returning a stitched image showing the defined circles
            "blob": uses self.center_blob_spot()
            "line_peaks": uses self.center_peak_spot()
            None: defaults to defining an ellipsoid based on the height and width of each spot image snippet

        Args:
            spot_images (dict): a dictionary of spot coordinates where the value is a tuple of (top_left_corner, spot_image)
            dilation_factor (float): a multiplier to enlarge or constrict the defined constraining ellipsoid
            centering_mode (str): mode for how to center and constrain the spot ellipsoid
            return_coordinates_list (bool): whether to reutrn a list of coordinates for the spots, in addition to the results dictionary
            verbose (bool): whether to display debugging information

        Returns:
            output_dict (dict): a dictionary of spot coordinates where the value is a tuple of (unadjusted_signal, background_adjusted_signal, ellipsoid_index, spot_midpoint, top_left_corner, stitched_image)
        '''

        print("\t\t\trunning ellipsoid_constrain()...") if verbose else None

        # Get the minimum spot radius of all spots in the dictionary
        spot_radii_list = []
        for values_dict in spot_images.values():
            spot_image_radius = values_dict.get("spot_radius")
            spot_radii_list.append(spot_image_radius)
        spot_radius_min = min(spot_radii_list)

        # Perform spot image quantification
        output_dict = {}
        coordinates_list = []
        image_stitching_list = []
        final_midpoints_list = []

        for spot_coordinates, values_dict in spot_images.items():
            top_left_corner = values_dict.get("top_left_corner")
            spot_midpoint_coords = values_dict.get("spot_midpoint_coords")
            spot_image = values_dict.get("spot_image_snippet")

            print("\t\t\ttop left corner of current spot:", top_left_corner) if verbose else None

            spot_image_height = len(spot_image)
            spot_image_width = len(spot_image[0])

            print("\t\t\tSpot image height: ", spot_image_height, "px", "\n\t\t\tSpot image width: ", spot_image_width, "px") if verbose else None

            if centering_mode == "iterative":
                final_midpoint_coords, results = spot_circle_scan(image_snippet = spot_image, source_image = self.linear_array,
                                                                  midpoint_coords = spot_midpoint_coords, enforced_radius = spot_radius_min,
                                                                  alphanumeric_coords = spot_coordinates, radius_variance_multiplier = 0.33,
                                                                  radius_shrink_multiplier = 0.9, value_to_maximize = "inside_sum", verbose = False)

                # Append midpoint coordinates to the list for drawing circles later
                final_midpoints_list.append(final_midpoint_coords)

                # Declare quantified metrics
                ellipsoid_index = results.get("ellipsoid_index")
                spot_midpoint = results.get("spot_midpoint")
                mean_intensity_outside = results.get("outside_sum") / results.get("outside_count")
                background_adjusted_signal = results.get("inside_sum") - (results.get("inside_count") * mean_intensity_outside)
                unadjusted_signal = results.get("inside_sum")

            elif centering_mode == "hough" or centering_mode == "hough_stitch":
                results = hough_detect_circle(spot_image, dilate_to_edge = True, verbose = True)
                ellipsoid_index = results.get("ellipsoid_index")
                spot_midpoint = results.get("spot_midpoint")
                mean_intensity_outside = results.get("outside_sum") / results.get("outside_count")
                background_adjusted_signal = results.get("inside_sum") - (results.get("inside_count") * mean_intensity_outside)
                unadjusted_signal = results.get("inside_sum")
                if centering_mode == "hough_stitch":
                    image_for_stitching = results.get("outlined_image")
                    image_stitching_list.append((image_for_stitching, top_left_corner))

            else:
                print("\t\t\tcaution: centering_mode", centering_mode, "is not recognized; defaulting to None") if centering_mode != None else None
                spot_radii = np.array([round((spot_image_height / 2) * dilation_factor), round((spot_image_width / 2) * dilation_factor)])
                spot_midpoint = (spot_radii[0], spot_radii[1])
                spot_radius = spot_radii.min() * dilation_factor  # enforce circles when ellipsoids are oblong
                pixels_inside, pixels_outside, unadjusted_signal, sum_outside, ellipsoid_index, background_adjusted_signal = circle_stats(grayscale_image, center = spot_midpoint, radius = spot_radius)

            # To the output dict, add a tuple containing the background-adjusted signal and the ellipsoid index
            output_dict[spot_coordinates] = (unadjusted_signal, background_adjusted_signal, ellipsoid_index, spot_midpoint, top_left_corner)
            coordinates_list.append(spot_coordinates)

        # If a method was used that supports circling the detected spots, generate an image showing circles in green
        if centering_mode == "iterative":
            outlined_image = draw_color_circle(self.sliced_image, final_midpoints_list, spot_radius_min, "green")
        elif centering_mode == "hough_stitch":
            outlined_image = concatenate_images(image_stitching_list)
        else:
            outlined_image = None

        '''
        Returns a dictionary where the key is spot coordinates and the value is a tuple containing 
        (background-adjusted signal, ellipsoid index)
        '''
        if return_coordinates_list:
            return outlined_image, output_dict, coordinates_list
        else:
            return outlined_image, output_dict

    #-------------------------------------------------------------------------------------------------------------------------------------------------------
    '''
    Function to draw crosshairs on the true peak points for each spot in the unsliced image. 
    As input, takes: 
        image = an image as a numpy array
        spot_info = the dictionary returned by ellipsoid_constrain()
        crosshair_length = the length, in pixels, of the crosshair lines to be drawn
        crosshair_brightness = the brightness of the drawn crosshairs as a float pixel intensity (max. 1.0)
        crosshair_width = the width of the crosshair lines. Must be an odd integer; if not odd, +1 will be added. 
    Returns the image with crosshairs drawn on all the spots. 
    '''
    def draw_crosshairs(self, color_image, spot_info, crosshair_diameter = 5, crosshair_width = 3):
        max_green_pixel = color_image[:,:,1].max()

        if crosshair_width % 2 == 0:
            crosshair_width = crosshair_width + 1  # catches even widths

        deviation = int((crosshair_width - 1) / 2)

        for spot_coordinates, value_tuple in spot_info.items():
            unadjusted_signal, background_adjusted_signal, ellipsoid_index, peak_intersect, top_left_corner = value_tuple
            real_peak_intersect = (top_left_corner[0] + peak_intersect[0], top_left_corner[1] + peak_intersect[1])

            # Draw horizontal green crosshair
            color_image[:,:,1][real_peak_intersect[0] - deviation: real_peak_intersect[0] + deviation, real_peak_intersect[1] - crosshair_diameter: real_peak_intersect[1] + crosshair_diameter] = max_green_pixel
            color_image[:,:,[0,2]][real_peak_intersect[0] - deviation: real_peak_intersect[0] + deviation, real_peak_intersect[1] - crosshair_diameter: real_peak_intersect[1] + crosshair_diameter] = 0

            # Draw vertical green crosshair
            color_image[:,:,1][real_peak_intersect[0] - crosshair_diameter: real_peak_intersect[0] + crosshair_diameter, real_peak_intersect[1] - deviation: real_peak_intersect[1] + deviation] = max_green_pixel
            color_image[:,:,[0,2]][real_peak_intersect[0] - crosshair_diameter: real_peak_intersect[0] + crosshair_diameter, real_peak_intersect[1] - deviation: real_peak_intersect[1] + deviation] = 0

        return color_image

#---------------------------------------------------------------------------------------------------------------------------------------------
#Begin processing the images

def main():
    print("Please enter the dimensions of the array (number of spots in width x number of spots in height).")

    spot_grid_width = input_number(prompt = "Width (number of spots):  ", mode = "int")
    spot_grid_height = input_number(prompt = "Height (number of spots):  ", mode = "int")
    spot_grid_dimensions = (spot_grid_width, spot_grid_height)
    print("-----------------------")

    image_directory = input("Enter the full directory where TIFF images are stored: ")
    filenames_list = os.listdir(image_directory)
    print("Loading and processing files as SpotArray objects...")
    spot_arrays = []
    for filename in filenames_list:
        print("\tLoading", filename)
        file_path = os.path.join(image_directory, filename)

        # Extract metadata from filename
        filename_elements = filename.split("_")
        metadata_tuple = (filename_elements[0], filename_elements[1][4:], filename_elements[2][4:])

        spot_array = SpotArray(tiff_path = file_path, spot_dimensions = spot_grid_dimensions, metadata = metadata_tuple,
                               suppress_warnings = False, pixel_log_base = 1, verbose = True)
        spot_arrays.append(spot_array)

    print("-----------------------")
    print("Assembling dataframe and saving images...")

    data_df = pd.DataFrame() #initialize blank dataframe

    # Declare output directories and ensure that they exist
    output_dirs = {
        "output": os.path.join(os.getcwd(), "image_prep_output"),
        "rlt_output": os.path.join(os.getcwd(), "image_prep_output", "reverse_log_transformed_images"),
        "crosshairs_output": os.path.join(os.getcwd(), "image_prep_output", "crosshairs-marked_spot_images")
    }
    for name, path in output_dirs.items():
        if not os.path.exists(path):
            os.makedirs(path)

    bas_cols_dict = {} #Dictionary of lists of background-adjusted signal column names, where the key is the probe name
    ei_cols_dict = {} #Dictionary of lists of ellipsoid index column names, where the key is the probe name
    new_cols_dict = {} #Dictionary that includes both of the above, along with the copy and scan numbers, in the form of (copy, scan, bas_col, ei_col)

    for spot_array in spot_arrays:
        col_prefix = spot_array.probe_name + "\nCopy " + str(spot_array.copy_number) + "\nScan " + str(spot_array.scan_number)
        uas_col = col_prefix + "\nRaw_Spot_Signal"
        bas_col = col_prefix + "\nBackground-Adjusted_Signal"
        ei_col = col_prefix + "\nEllipsoid_Index"

        #Assign column names to dict by probe name
        dict_value_append(bas_cols_dict, spot_array.probe_name, bas_col)
        dict_value_append(ei_cols_dict, spot_array.probe_name, ei_col)
        dict_value_append(new_cols_dict, spot_array.probe_name, (spot_array.copy_number, spot_array.scan_number, bas_col, ei_col))

        #Assign dataframe values
        for spot_coord, signal_tuple in spot_array.spot_info_dict.items():
            unadjusted_signal, background_adjusted_signal, ellipsoid_index, _, _ = signal_tuple

            data_df.at[spot_coord, uas_col] = unadjusted_signal
            data_df.at[spot_coord, bas_col] = background_adjusted_signal
            data_df.at[spot_coord, ei_col] = ellipsoid_index

        #Save modified image
        imwrite(os.path.join(output_dirs.get("rlt_output"), "Copy" + str(spot_array.copy_number) + "_Scan" + str(spot_array.scan_number) + "_" + spot_array.probe_name + "_reverse-log-transform.tif"), spot_array.linear_array)
        imwrite(os.path.join(output_dirs.get("crosshairs_output"), "Copy" + str(spot_array.copy_number) + "_Scan" + str(spot_array.scan_number) + "_" + spot_array.probe_name + "_crosshairs.tif"), spot_array.outlined_image)

    #Declare probe order for sorting dataframe columns
    probes_ordered = []
    input_probe_order = input("Would you like to specify the order of probes for sorting columns? (Y/N)  ")
    if input_probe_order == "Y":
        print("\tThe probes in this dataset are:", list(ei_cols_dict.keys()))
        print("\tPlease enter the probes in the order you wish them to appear. Hit enter when done.")
        no_more_probes = False
        while not no_more_probes:
            next_probe = input("Probe name:  ")
            if next_probe != "":
                probes_ordered.append(next_probe)
            else:
                no_more_probes = True
    else:
        probes_ordered = list(ei_cols_dict.keys())
        print("\tUsing arbitrary probe order:", probes_ordered)

    #Sorting dataframe and testing significance of hits
    print("Organizing dataframe...")

    sorted_cols = ["Peptide_Name"] #Adds a column to receive peptide names later
    data_df.insert(0, "Peptide_Name", "")
    for current_probe in probes_ordered:
        col_tuples = new_cols_dict.get(current_probe)
        col_tuples = sorted(col_tuples, key = lambda x: x[0]) #Sorts by copy number
        new_cols_dict[current_probe] = col_tuples
        for col_tuple in col_tuples:
            sorted_cols.append(col_tuple[2]) #Appends background_adjusted_signal column name
            sorted_cols.append(col_tuple[3]) #Appends ellipsoid_index column name
        data_df.insert(1, current_probe + "_call", "")
        sorted_cols.append(current_probe + "_call")

    data_df = data_df[sorted_cols]

    #Test significance
    print("Testing significance of hits...")
    ei_sig_thres = float(input("\tEnter the ellipsoid index threshold above which a hit is considered significant:  "))

    for current_probe in probes_ordered:
        call_col = current_probe + "_call"
        ei_cols = ei_cols_dict.get(current_probe)
        data_df[call_col] = data_df.apply(lambda x: "Pass" if (x[ei_cols] > ei_sig_thres).all() else "", axis = 1)

    #Add peptide names
    add_names = input("Add peptide names from CSV file mapping coordinates to names? (Y/N)  ")
    if add_names == "Y":
        names_path = input("\tEnter the path containing the CSV with coordinate-name pairs:  ")
        names_dict = csv_to_dict(names_path)
        for i, row in data_df.iterrows():
            pep_name = names_dict.get(i)
            data_df.at[i, "Peptide_Name"] = pep_name

    data_df.to_csv(os.path.join(output_dirs.get("output"), "preprocessed_data.csv"))

    print("Done!")

if __name__ == "__main__":
    main()