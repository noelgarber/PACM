'''
This script performs image quantification of arrays of spots.
It was developed for SPOT peptide arrays, but it can be used for any image containing a grid of spots with rows and columns.
Note:   images inputted into this algorithm should be pre-straightened and cropped to the borders of the actual
        grid of spots. Leave no surrounding black space.
The data generated by this algorithm is compatible with the rest of the PACM pipeline.
'''

import numpy as np
import pandas as pd
import os
from general_utils.general_utils import input_number, csv_to_dict, dict_value_append
from Matrix_Generator.image_processing.SpotArray import SpotArray
from tifffile import imwrite

def get_grid_dimensions(verbose = True):
    print("Please enter the dimensions of the array (number of spots in width x number of spots in height).")
    spot_grid_width = input_number(prompt = "Width (number of spots):  ", mode = "int")
    spot_grid_height = input_number(prompt = "Height (number of spots):  ", mode = "int")
    spot_grid_dimensions = (spot_grid_width, spot_grid_height)
    print("-----------------------") if verbose else None
    return spot_grid_dimensions

def load_spot_arrays(filenames_list, image_directory, spot_grid_dimensions, pixel_log_base = 1, verbose = True):
    spot_arrays = []
    for filename in filenames_list:
        print("\tLoading", filename) if verbose else None
        file_path = os.path.join(image_directory, filename)

        # Extract metadata from filename
        filename_elements = filename.split("_")
        metadata_tuple = (filename_elements[0], filename_elements[1][4:], filename_elements[2][4:])

        spot_array = SpotArray(tiff_path = file_path, spot_dimensions = spot_grid_dimensions, metadata = metadata_tuple,
                               show_sliced_image = False, show_outlined_image = False, suppress_warnings = False,
                               pixel_log_base = pixel_log_base, verbose = verbose)
        spot_arrays.append(spot_array)
    print("-----------------------") if verbose else None
    return spot_arrays

# Declare output directories and ensure that they exist
def declare_output_dirs(parent_directory = None):
    '''
    Function for declaring output directories for preprocessed data and image files

    Args:
        parent_directory (str): folder into which subfolders containing output data should be placed

    Returns:
        output_dirs (dict): dictionary of output directories for "output" (quantified data),
                            "rlt_output" (linear grayscale images), and "outlined_output" (outlined images)
    '''

    # If no parent directory was given, declare parent directory as current working directory
    if parent_directory is None:
        # Warning: if this script is run for multiple datasets, data will be overwritten when no parent_directory is given
        parent_directory = os.getcwd()

    # Declare output directories
    output_dirs = {
        "output": parent_directory,
        "rlt_output": os.path.join(parent_directory, "linear_images"),
        "outlined_output": os.path.join(parent_directory, "outlined_spot_images")
    }

    # Check if the directories exist, and if not, make them
    for name, path in output_dirs.items():
        if not os.path.exists(path):
            os.makedirs(path)

    return output_dirs

def assign_data_values(data_df, spot_arrays, multiline_cols = True):
    uas_cols_dict = {} # Dictionary of lists of unadjusted signal column names, where the key is the probe name
    bas_cols_dict = {} # Dictionary of lists of background-adjusted signal column names, where the key is the probe name
    ei_cols_dict = {}  # Dictionary of lists of ellipsoid index column names, where the key is the probe name
    new_cols_dict = {} # Dictionary that includes both of the above, along with the copy and scan numbers, in the form of (copy, scan, bas_col, ei_col)

    for spot_array in spot_arrays:
        if multiline_cols:
            col_prefix = spot_array.probe_name + "\nCopy " + str(spot_array.copy_number) + "\nScan " + str(spot_array.scan_number)
            uas_col = col_prefix + "\nRaw_Spot_Signal"
            bas_col = col_prefix + "\nBackground-Adjusted_Signal"
            ei_col = col_prefix + "\nEllipsoid_Index"
        else:
            col_prefix = spot_array.probe_name + "_Copy-" + str(spot_array.copy_number)
            uas_col = col_prefix + "_Raw_Spot_Signal"
            bas_col = col_prefix + "_Background-Adjusted_Signal"
            ei_col = col_prefix + "_Ellipsoid_Index"

        #Assign column names to dict by probe name
        dict_value_append(uas_cols_dict, spot_array.probe_name, uas_col)
        dict_value_append(bas_cols_dict, spot_array.probe_name, bas_col)
        dict_value_append(ei_cols_dict, spot_array.probe_name, ei_col)
        dict_value_append(new_cols_dict, spot_array.probe_name, (spot_array.copy_number, spot_array.scan_number, uas_col, bas_col, ei_col))

        #Assign dataframe values
        for spot_coord, signal_tuple in spot_array.spot_info_dict.items():
            unadjusted_signal, background_adjusted_signal, ellipsoid_index, _, _ = signal_tuple

            data_df.at[spot_coord, uas_col] = unadjusted_signal
            data_df.at[spot_coord, bas_col] = background_adjusted_signal
            data_df.at[spot_coord, ei_col] = ellipsoid_index

    # Return dicts of column names
    return uas_cols_dict, bas_cols_dict, ei_cols_dict, new_cols_dict

def write_images(output_dirs, spot_arrays):
    for spot_array in spot_arrays:
        #Save modified image
        linear_directory = os.path.join(output_dirs.get("rlt_output"), "Copy" + str(spot_array.copy_number) + "_" + spot_array.probe_name + "_linear.tif")
        imwrite(linear_directory, spot_array.linear_array)

        outlined_directory = os.path.join(output_dirs.get("outlined_output"), "Copy" + str(spot_array.copy_number) + "_" + spot_array.probe_name + "_outlined.tif")
        imwrite(outlined_directory, spot_array.outlined_image)

def get_probe_order(probes_list):
    probes_ordered = []
    input_probe_order = input("Would you like to specify the order of probes for sorting columns and/or drop some probes? (Y/N)  ")
    if input_probe_order == "Y":
        print("\tThe probes in this dataset are:", probes_list)
        print("\tEnter the probes in the order you wish them to appear. If a probe is omitted, it is dropped. Hit enter when done.")
        no_more_probes = False
        while not no_more_probes:
            next_probe = input("Probe name:  ")
            if next_probe != "":
                probes_ordered.append(next_probe)
            else:
                no_more_probes = True
    else:
        probes_ordered = probes_list
    return probes_ordered

def prepare_sorted_cols(data_df, probes_ordered, cols_dict):
    sorted_cols = ["Peptide_Name"] # Adds a column to receive peptide names later
    data_df.insert(0, "Peptide_Name", "")
    for current_probe in probes_ordered:
        col_tuples = cols_dict.get(current_probe)
        col_tuples = sorted(col_tuples, key = lambda x: x[0]) #Sorts by copy number
        cols_dict[current_probe] = col_tuples
        for col_tuple in col_tuples:
            sorted_cols.append(col_tuple[2]) # Appends unadjusted signal column name
            sorted_cols.append(col_tuple[3]) # Appends background_adjusted_signal column name
            sorted_cols.append(col_tuple[4]) # Appends ellipsoid_index column name
        data_df.insert(1, current_probe + "_call", "")
        sorted_cols.append(current_probe + "_call")

    # Sort dataframe
    data_df = data_df[sorted_cols]
    return data_df

def significance_testing(data_df, ei_cols_dict, probes_ordered, ei_sig_thres = None):
    if ei_sig_thres is None:
        ei_sig_thres = input_number(prompt = "Enter the ellipsoid index threshold above which a hit is considered significant:  ", mode = "float")

    for current_probe in probes_ordered:
        call_col = current_probe + "_call"
        ei_cols = ei_cols_dict.get(current_probe)
        data_df[call_col] = data_df.apply(lambda x: "Pass" if (x[ei_cols] > ei_sig_thres).all() else "", axis = 1)

def add_peptide_names(data_df, names_path = None):
    if names_path is None:
        names_path = input("\tEnter the path containing the CSV with coordinate-name pairs:  ")
    names_dict = csv_to_dict(names_path)
    for i, row in data_df.iterrows():
        pep_name = names_dict.get(i)
        data_df.at[i, "Peptide_Name"] = pep_name

def main_preprocessing(image_directory = None, spot_grid_dimensions = None, output_dirs = None, peptide_names_path = None, ellipsoid_index_thres = None, probes_ordered = None, multiline_cols = True, verbose = True):
    if spot_grid_dimensions is None:
        spot_grid_dimensions = get_grid_dimensions(verbose = verbose)
    if image_directory is None:
        image_directory = input("Enter the full directory where TIFF images are stored: ")
    filenames_list = os.listdir(image_directory)

    # Load images as SpotArray objects
    print("Loading and processing files as SpotArray objects...") if verbose else None
    spot_arrays = load_spot_arrays(filenames_list = filenames_list, image_directory = image_directory,
                                   spot_grid_dimensions = spot_grid_dimensions, pixel_log_base = 1, verbose = verbose)

    # Assemble a dataframe containing results values
    print("Assembling dataframe and saving images...") if verbose else None
    data_df = pd.DataFrame()
    uas_cols_dict, bas_cols_dict, ei_cols_dict, new_cols_dict = assign_data_values(data_df = data_df, spot_arrays = spot_arrays, multiline_cols = multiline_cols)

    # Write output images to destination directories
    if output_dirs is None:
        parent_dir = input("Please enter the directory where outlined images for this dataset should be deposited: ")
        output_dirs = declare_output_dirs(parent_directory = parent_dir)
    write_images(output_dirs = output_dirs, spot_arrays = spot_arrays)

    # Declare probe order for sorting dataframe columns
    if probes_ordered is None:
        probes_list = list(ei_cols_dict.keys())
        probes_ordered = get_probe_order(probes_list = probes_list)

    #Sorting dataframe and testing significance of hits
    print("Organizing dataframe and testing hit significance...") if verbose else None
    data_df = prepare_sorted_cols(data_df = data_df, probes_ordered = probes_ordered, cols_dict = new_cols_dict)
    if ellipsoid_index_thres is None:
        significance_testing(data_df = data_df, ei_cols_dict = ei_cols_dict, probes_ordered = probes_ordered)
    else:
        significance_testing(data_df = data_df, ei_cols_dict = ei_cols_dict, probes_ordered = probes_ordered, ei_sig_thres = ellipsoid_index_thres)

    # Add peptide names
    if peptide_names_path is None:
        add_names = input("Add peptide names from CSV file mapping coordinates to names? (Y/N)  ")
        if add_names == "Y" or add_names == "y":
            add_peptide_names(data_df = data_df)
    else:
        add_peptide_names(data_df = data_df, names_path = peptide_names_path)

    # Save completed dataframe
    data_df.to_csv(os.path.join(output_dirs.get("output"), "preprocessed_data.csv"))

    print("Done!") if verbose else None

    # Return dataframe, which can be optionally assigned when main() is invoked
    return data_df

if __name__ == "__main__":
    main_preprocessing()